---
sidebar_position: 2
sidebar_label: 安装环境准备
---

## 安装部署计划

| 主机          | 规划设置主机名 | 角色                                            |
|--------------|-----------------  |-------------------------------------------------|
| 10.240.8.68  | master1           | NameNode、DataNode、ResourceManager、NodeManager |
| 10.240.8.229 | master2           | SecondaryNameNode、DataNode、NodeManager        |
| 10.240.8.185 | node1             | DataNode、NodeManager                           |


## 安装包准备

### Hadoop 

```
【超级会员V5】通过百度网盘分享的文件：hadoop-3…
链接:https://pan.baidu.com/s/1Mps1As9-DHkNblLSHBRHkg 
提取码:u22u
复制这段内容打开「百度网盘APP 即可获取」
```

### JDK

```
【超级会员V5】通过百度网盘分享的文件：jdk-8u16…
链接:https://pan.baidu.com/s/1SrpBXR4R0a2-dOZjw5BB2w 
提取码:61q4
复制这段内容打开「百度网盘APP 即可获取」
```

### ZK

```
【超级会员V5】通过百度网盘分享的文件：apache-z…
链接:https://pan.baidu.com/s/1tnL0CzTp9kVAcvaO45Ce4g 
提取码:144s
复制这段内容打开「百度网盘APP 即可获取」
```
## Linux 前期准备

- 关闭防火墙。
```
systemctl stop firewalld
systemctl disable firewalld.service
```

- 关闭selinux。

    - 临时关闭：输入命令setenforce 0，重启系统后还会开启。

    - 永久关闭：输入命令vi /etc/selinux/config，将SELINUX=enforcing改为SELINUX=disabled，然后保存退出。

- 创建大数据对应的用户。

```
useradd bigdata
passwd bigdata
```
- 修改用户资源限制。

```
sudo vi /etc/security/limits.conf
 
bigdata soft nofile 65536
bigdata hard nofile 65536
bigdata soft nproc 131072
bigdata hard nproc 131072
 
sudo vi /etc/security/limits.d/20-nproc.conf

bigdata soft nofile 65536
bigdata hard nofile 65536
bigdata soft nproc 131072
bigdata hard nproc 131072
```

- 配置用户的sudo权限。

```
vim /etc/sudoers
## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL
 
## Allows people in group wheel to run all commands
%wheel  ALL=(ALL)       ALL
bigdata   ALL=(ALL)     NOPASSWD:ALL
```
> 注意： bigdata 这一行不要直接放到root行下面，因为所有用户都属于wheel组，你先配置了 bigdata 具有免密功能，**但是程序执行到%wheel行时，该功能又被覆盖回需要密码**。所以 bigdata 要放到%wheel这行下面。

- 用户进程最大化使用资源。

```
sudo sh -c 'echo 1 > /proc/sys/vm/overcommit_memory'
```

- 创建对应的目录。

    - /home/bigdata/software : 用来放安装包。
    - /home/bigdata/module：用来放解压后的安装包。

```
mkdir /home/bigdata/module
mkdir /home/bigdata/software
mkdir /home/bigdata/shell
chown bigdata:bigdata /home/bigdata/module
chown bigdata:bigdata /home/bigdata/software
chown bigdata:bigdata /home/bigdata/shell
```

- 卸载linux自带的JDK。

```
rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps
```

- 修改主机hostname。

```
<!-- 分别修改对应机器的hostname,注意就是这里的hostname和下面的/etc/hosts记得要一致，不然会出现莫名其妙的问题。 -->
vim /etc/hostname

sudo hostname master1
sudo hostname master2
sudo hostname node1
```

- 配置本地DNS。

```
把127.0.0.1给删除，不然会出现wordcount都运行不了。

vim /etc/hosts

10.240.8.68  master1
10.240.8.229 master2
10.240.8.185 node1
```

> 如果出现运行wordcount卡住的情况，那么可能是/etc/hosts对应的127.0.0.1影响了，注解掉，重启hadoop。

- 配置ssh免密登录。

```
su - bigdata
ssh-keygen
ssh-copy-id master1
ssh-copy-id master2
ssh-copy-id node1
```

## 配置 JDK 环境。

- 解压安装包。

```
tar -zxvf jdk-8u161-linux-x64.tar.gz -C ../module/
```

```
sudo vim /etc/profile.d/my_env.sh

#JAVA_HOME
export JAVA_HOME=/home/bigdata/module/jdk1.8.0_161
export PATH=$PATH:$JAVA_HOME/bin

source /etc/profile.d/my_env.sh
```

## 添加集群分发脚本

```
vi /home/bigdata/shell/xsync.sh
```

```
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
  echo Not Enough Arguement!
  exit;
fi
#2. 遍历集群所有机器
for host in master1 master2 node1
do
  echo ====================  $host  ====================
  #3. 遍历所有目录，挨个发送
  for file in $@
  do
    #4 判断文件是否存在
    if [ -e $file ]
    then
      #5. 获取父目录
      pdir=$(cd -P $(dirname $file); pwd)
      #6. 获取当前文件的名称
      fname=$(basename $file)
      ssh $host "mkdir -p $pdir"
      rsync -av $pdir/$fname $host:$pdir
    else
      echo $file does not exists!
    fi
  done
done
```

**给予执行权限**

```
chmod 777 /home/bigdata/shell/xsync.sh
```

安装 linux 集群的同步工具

```
sudo yum install -y rsync
```

分发 JDK 到其他的机器

```
/home/bigdata/shell/xsync.sh /home/bigdata/module/jdk1.8.0_161

<!-- 如果不执行这个命令，那么下面同步环境变量文件的时候，就需要集群里面的root用户都是免密的才行 -->
sudo chmod 777 -R /etc/profile.d/

/home/bigdata/shell/xsync.sh /etc/profile.d/my_env.sh
```

所有机器都执行

```
source /etc/profile.d/my_env.sh
```

> 到这里如果在所有的机器的 JDK 都可以用了，那么基础环境就好了，下面就是配置 Zookeeper 集群了,然后就是 Hadoop 集群的高可用，配置 Zk 的时候在zk专栏看怎么配置集群和注意事项，这里就不做重复操作了。